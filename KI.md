# Künstliche Intelligenz
* Tensorflow Playground: [Tinker With a Neural Network Right Here in Your Browser.](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.25732&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) Don’t Worry, You Can’t Break It. We Promise.
* [Geospy AI](https://geospy.ai/) Welcome to GeoSpy Public Demo. Photo location prediction using AI. Take a picture or select an existing one.
* [Quillbot](https://quillbot.com/) QuillBot's AI-powered paraphrasing tool will enhance your writing
* [GPT minus 1](https://www.gptminus1.com/) Fool GPT by randomly replacing words with synonyms in your text. Diese Seite wird von einigen Scannern als Malware gelistet. Bitte mit Vorsicht nutzen
  * [GPT minus 1](https://ai-search.io/tool/gptminus1)
* [Trickmenot.ai](https://trickmenot.ai/) tricks to avoid AI detection
* [Originality.ai](https://originality.ai/) The most accurate Chat GPT, Bard, Paraphrasing, and GPT-4 AI checker built specifically for content marketers and SEOs.
* Tomtlok: [KI-Detektor-Demoversion](https://tomtlok.de/demo) Unser KI-Detektor setzt fortschrittliche Algorithmen und maschinelles Lernen ein, um subtile Unterschiede in Sprachmustern, Stil und Struktur zu erkennen, die typischerweise KI-generierte Texte charakterisieren. Entdecke, wie effektiv unsere Technologie deutschsprachige KI-Inhalte identifiziert. Die Demo-Version ist ausschließlich für die Erkennung von durch GPT-3.5 generierten Texten und für Fließtexte zugeschnitten
  * FH Wedel: [Erkennung von KI-generierten Texten](https://ki.fh-wedel.de/) basiert auf Tom Tlok
* [Prozess zur rechtskonformen Einführung / Einsatz von KI im Unternehmen](https://fbgw.h-da.de/forschung/chatgpt-dall-e-co/vorgehensmodell-ki-einfuehrung) Der KI-Einsatz sollte sorgfältig geplant sein, wichtig ist vor allem Transparenz sowohl hinsichtlich der Einbeziehung der KI, als auch der Qualitätssicherung der Trainingsdaten und Ergebnisse sowie der Einbindung von API-Schnittstellen. Ein verstärkter Einsatz in den Feldern ECM / DMS, ERP und E-Mail-Management ist zu beobachten, eine Ausweitung auf andere Felder – weit über Textgenerierungsfunktionen hinaus - steht in vielen Unternehmen bevor (siehe https://www.bitkom.org/Presse/Presseinformation/ChatGPT-Jedes-sechste-Unternehmen-plant-KI-Einsatz-Textgenerierung).
* https://www.bigdata-ai.fraunhofer.de/de/data-scientist/ai-for-schools.html
* https://fobizz.com/
* https://interscience-akademie.de/2021/10/19/ki-algorithmen-im-informatik-unterricht/
* https://www.br.de/nachrichten/netzwelt/chatgpt-schafft-die-ki-das-bayerische-abitur,TVBjrXE (Feb. 2023)
* https://www.br.de/nachrichten/netzwelt/chatgpt-so-gut-hat-die-ki-das-bayerische-abitur-bestanden,TfB3QBw (Mai 2023)
* https://www.br.de/nachrichten/bayern/bayerns-lehrerverband-will-wegen-ki-klassische-noten-abschaffen,TfQY923
  die Bundeszentrale für politische Bildung aktualisiert diesbezüglich ständig. 
* Alan Turing: 
  * https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf (das Original) 
* [Create Stories for Kids using AI](https://storybee.app/) Generate kids' Stories anytime with our AI-powered Story platform.
* Hans-Böckler-Stiftung: [Künstliche Intelligenz, Large Language Models, Chatgpt und die Arbeitswelt der Zukunft](https://www.boeckler.de/de/faust-detail.htm?sync_id=HBS-008697) Die rasante Entwicklung von Systemen Künstlicher Intelligenz wie Chat-GPT, die inhaltlich und sprachlich überzeugende Texte generieren können, hat eine intensive Debatte ausgelöst. Es stellt sich die Frage, welche Auswirkungen solche Systeme auf die Prozesse und Arbeitsweisen zum Beispiel in Wissens- und Kreativberufen haben werden. Diese Literaturstudie wertet den aktuellen Stand der Debatte aus. Sie führt in die technische Grundlage, die so genannten "Large Language Models", ein und untersucht abschließend, welche Auswirkungen auf die Arbeitswelt zu erwarten sind. (von Michael Seemann)
* ctrl+verlust: [Was sind Large Language Models und wie funktionieren sie?](https://www.ctrl-verlust.net/was-sind-large-language-models-und-wie-funktionieren-sie/) Large Language Models (LLMs) sind in aller Munde, aber kaum jemand versteht, wie sie funktionieren. Es gibt einige ganz gute Explainer in englischer Sprache, aber keine wirklich guten in Deutsch (jedenfalls ist mir keiner untergekommen). Dies ist ein Auszug aus der Literaturstudie: „Künstliche Intelligenz, Large Language Models, ChatGPT und die Arbeitswelt der Zukunft“, die Michael Seemann für die Hans-Böckler-Stiftung erstellt hat. Er hat den Erklärteil zu LLMs herausgelöst, um ein breiteres Verständnis für die Technologie zugänglicher zu machen.
* Trolley-Problem
  * [Moral Machine](https://www.moralmachine.net/)
  * [Absurd Trolley Problems](https://neal.fun/absurd-trolley-problems/)
* [Does GPT-4 pass the Turing Test?](https://arxiv.org/abs/2310.20216) We evaluated GPT-4 in a public online Turing Test. The best-performing GPT-4 prompt passed in 41% of games, outperforming baselines set by ELIZA (27%) and GPT-3.5 (14%), but falling short of chance and the baseline set by human participants (63%). Participants' decisions were based mainly on linguistic style (35%) and socio-emotional traits (27%), supporting the idea that intelligence is not sufficient to pass the Turing Test. Participants' demographics, including education and familiarity with LLMs, did not predict detection rate, suggesting that even those who understand systems deeply and interact with them frequently may be susceptible to deception. Despite known limitations as a test of intelligence, we argue that the Turing Test continues to be relevant as an assessment of naturalistic communication and deception. AI models with the ability to masquerade as humans could have widespread societal consequences, and we analyse the effectiveness of different strategies and criteria for judging humanlikeness.
* [ChatGPT Is Hilariously Bad at Generating Random Numbers](https://futurism.com/the-byte/chatgpt-random-numbers) If you need random numbers generated, steer clear of ChatGPT. Unless you want responses to be less random and more poisoned by human preferences, that is.
* ["Gesunder Menschenverstand" für Maschinen: Metas Weg zur allgemeinen KI](https://heise.de/-7153533) Wie Meta die lang erhoffte "Artificial General Intelligence" will, hatte der Leiter der Forschungsabteilung Yann LeCun im Sommer 2022 skizziert.
* [Künstliche Allgemeine Intelligenz: Wissen, was wahr ist](https://heise.de/-5058948) Könnte der Traum von einer denkenden, menschenähnlichen Maschine wirklich wahr werden? Die Frage wird derzeit heftiger denn je diskutiert.
* Kristian Koehntopp: [Wie ChatGPT funktioniert](https://blog.koehntopp.info/2024/02/06/wie-chatgpt-funktioniert.html)
* Stephen Wolfram: [What Is ChatGPT Doing … and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)
* Input Consulting GmbH: [KI-Einsatz im Betrieb](https://www.input-consulting.de/publikationen.html?file=files/inpcon-DATA/download/2023_KI-Einsatz%20im%20Betrieb_FAQ%20Wedde.pdf) (PDF)
* heise: [Wie man KI-generierte Texte erkennen kann](https://www.heise.de/hintergrund/Wie-man-KI-generierte-Texte-erkennen-kann-7434812.html) Immer häufiger tauchen im Netz von Textgeneratoren erstellte Inhalte auf. Neue Werkzeuge müssen her, um sie zu erkennen. 
* Springer: [ChatGPT is bullshit](https://link.springer.com/article/10.1007/s10676-024-09775-5) Recently, there has been considerable interest in large language models: machine learning systems which produce human-like text and dialogue. Applications of these systems have been plagued by persistent inaccuracies in their output; these are often called “AI hallucinations”. We argue that these falsehoods, and the overall activity of large language models, is better understood as bullshit in the sense explored by Frankfurt (On Bullshit, Princeton, 2005): the models are in an important way indifferent to the truth of their outputs. We distinguish two ways in which the models can be said to be bullshitters, and argue that they clearly meet at least one of these definitions. We further argue that describing AI misrepresentations as bullshit is both a more useful and more accurate way of predicting and discussing the behaviour of these systems.
* Mike Kuketz: [KI lässt uns Menschen das Denken verlernen – und wir halten es für Fortschritt](https://www.kuketz-blog.de/ki-laesst-uns-menschen-das-denken-verlernen-und-wir-halten-es-fuer-fortschritt/) Künstliche Intelligenz gilt als Durchbruch – als »Meilenstein«, der unseren Alltag erleichtert, unsere Produktivität steigert und uns neue Horizonte eröffnet. Die Euphorie ist allgegenwärtig: Medien feiern »smarte Assistenten«, Konzerne versprechen »Lifehacks für jede Lebenslage«, und in der Werbung wird KI als verlängerter Arm unseres Denkens inszeniert. Doch bei aller Faszination über das technisch Mögliche übersehen viele, was sich still und gleichzeitig radikal verändert: Die Art, wie wir selbst denken – und wie oft wir es überhaupt noch tun.
* [Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task](https://arxiv.org/abs/2506.08872) This study explores the neural and behavioral consequences of LLM-assisted essay writing. Participants were divided into three groups: LLM, Search Engine, and Brain-only (no tools). Each completed three sessions under the same condition. In a fourth session, LLM users were reassigned to Brain-only group (LLM-to-Brain), and Brain-only users were reassigned to LLM condition (Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18 completing session 4. We used electroencephalography (EEG) to assess cognitive load during essay writing, and analyzed essays using NLP, as well as scoring essays with the help from human teachers and an AI judge. Across groups, NERs, n-gram patterns, and topic ontology showed within-group homogeneity. EEG revealed significant differences in brain connectivity: Brain-only participants exhibited the strongest, most distributed networks; Search Engine users showed moderate engagement; and LLM users displayed the weakest connectivity. Cognitive activity scaled down in relation to external tool use. In session 4, LLM-to-Brain participants showed reduced alpha and beta connectivity, indicating under-engagement. Brain-to-LLM users exhibited higher memory recall and activation of occipito-parietal and prefrontal areas, similar to Search Engine users. Self-reported ownership of essays was the lowest in the LLM group and the highest in the Brain-only group. LLM users also struggled to accurately quote their own work. While LLMs offer immediate convenience, our findings highlight potential cognitive costs. Over four months, LLM users consistently underperformed at neural, linguistic, and behavioral levels. These results raise concerns about the long-term educational implications of LLM reliance and underscore the need for deeper inquiry into AI's role in learning.
* Der Standard: [Atari 2600 von 1977 schlägt ChatGPT im Schach](https://www.derstandard.at/story/3000000273565/atari-2600-von-1977-schlaegt-chatgpt-im-schach) Die Legende der frühen Heimcomputer-Ära setzte sich trotz Anfängermodus durch. Das Ergebnis überrascht aber nur auf den ersten Blick
* [Wie funktioniert ChatGPT ganz genau? - Froscon 2024](https://www.youtube.com/watch?v=T7K2SmqlzOI) Eine Zeitreise durch Theorie und Funktionsweise von Sprachmodellen. Vortrag von Michael Christen bei der FrOSCon 2024. In diesem Vortrag wird die Funktionsweise von ChatGPT bis ins kleinste Detail beleuchtet. Wir bleiben dabei nicht auf einer oberflächigen Ebene sondern gehen vollständig ins Detail, bleiben aber allgemein verständlich.  Ausgehend von den historischen Wurzeln der KI-Forschung – wie den Arbeiten von Markov (Markov-Ketten für Textgenerierung) und Claude Shannon (Informationstheorie) – wird die Entwicklung moderner Sprachmodelle nachgezeichnet. Der Fokus liegt auf den bahnbrechenden Transformer-Architekturen und deren Schlüsselkomponenten: Embeddings, Attention (Bengio), Self-Attention und Multi-Head-Attention. Es wird gezeigt, wie neuronale Netze durch Backpropagation und Autoencoder (Hinton) lernen, Bedeutungszusammenhänge in hochdimensionalen Vektorräumen abzubilden. Die Rolle von Softmax-Aktivierung, Positional Encoding und Feedforward-Netzen wird ebenso erläutert wie der Übergang von reinen Textgeneratoren (GPT-3) zu dialogfähigen Systemen (ChatGPT) durch Instruct-Tuning und Reinforcement Learning. Ein besonderes Augenmerk gilt der Frage, ob solche Modelle tatsächlich „Verständnis“ entwickeln – diskutiert anhand des chinesischen Zimmers (Searle) und der These, dass Intelligenz auf Kompression beruht (Hutter, Hinton). Abschließend wird ein Ausblick auf zukünftige Entwicklungen wie planende KI-Systeme gegeben.
### 22.10.
* https://www.theregister.com/2024/10/20/asia_tech_news_roundup/
* https://www.heise.de/news/Von-KI-und-Freiheit-Hannah-Arendt-Tage-2024-in-Hannover-9989213.html
* https://t3n.de/news/ki-als-mediator-studie-1652682/
* https://www.youtube.com/watch?v=0fq1jlWcUv8
* https://arstechnica.com/tech-policy/2024/10/bytedance-intern-fired-for-planting-malicious-code-in-ai-models/
* https://youtu.be/pOuBCk8XMC8?si=tSJHgpG06uc6DnV0
* https://www.spiegel.de/netzwelt/30-jahre-spiegel-de-ein-blick-ins-jahr-2054-a-b79b8ee3-f5b9-4438-884d-ef49d2c12c1f
* https://newrepublic.com/article/187203/ai-radiology-geoffrey-hinton-nobel-prediction
* https://www.heise.de/news/Vision-Language-Modelle-versagen-bei-einfachen-Bildtests-9995946.html
* https://www.heise.de/hintergrund/Auslegungssache-109-Das-KI-DSGVO-Dilemma-9721822.html
* https://www.heise.de/news/Reasoning-Fail-Gaengige-LLMs-scheitern-an-kinderleichter-Aufgabe-9755034.html
* https://www.heise.de/news/Apple-Studie-Logisches-Denken-von-KI-kaum-nachweissbar-und-sehr-fragil-9980855.html
* https://www.giga.de/tech/externe-festplatte-fuers-gehirn-forscher-entdecken-revolutionaeres-system-0--01JAZ3MBBDZ3XREWG260XVDX04
* https://marketoonist.com/2024/03/potential-of-ai.html
* https://www.youtube.com/watch?v=fmwOu-C1AmI
* https://www.spiegel.de/auto/frankreich-vorsicht-vor-den-neuen-super-radarfallen-a-1b703b19-22f7-4baf-89e8-72d43c0d1203
* https://www.upi.com/Top_News/World-News/2024/11/01/Ireland-AI-fake-Halloween-parade-hoax/2311730467734/
* https://ebildungslabor.de/blog/fuenf-erkundungen-zur-neuen-such-funktion-von-chatgpt/
* https://dnip.ch/2024/10/29/wie-gut-verstehen-llms-die-welt/
* https://www.heise.de/news/KI-Technik-koennte-Elektroschrott-Menge-steigen-lassen-9997283.html
* https://www.derstandard.de/story/3000000207848/am-kopf-kratzen-bringt-380-euro-strafe-ki-versagt-als-strassenpolizist
* https://gizmodo.com/facial-recognition-that-tracks-suspicious-friendliness-is-coming-to-a-store-near-you-2000519190?utm_source=pocket-newtab-en-us
* DNIP: [Petzt die KI? Schlimm?](https://dnip.ch/2024/09/26/petzt-die-ki/) Es gibt viel Unsicherheit über Datenschutz und Datensicherheit rund um KI-Textgeneratoren wie ChatGPT oder Gemini. Was darf man ihnen anvertrauen? Was soll man lieber für sich selbst behalten? Eine Einordnung.
* DNIP: [Wie funktioniert eigentlich ChatGPT?](https://dnip.ch/2023/01/30/wie-funktioniert-eigentlich-chatgpt/) ChatGPT ist wohl das zur Zeit mächtigste Künstliche-Intelligenz-Sprachmodell. Wir schauen etwas hinter die Kulissen, wie das „large language model“ GPT-3 und das darauf aufsetzende ChatGPT funktionieren.
* DNIP: [Die Gefahr der faulen KI-Kritik](https://dnip.ch/2024/05/02/die-gefahr-der-faulen-ki-kritik/)
* DNIP: [Die dunklen Daten-Geheimnisse der KI](https://dnip.ch/2024/01/12/die-dunklen-daten-geheimnisse-der-ki/)
* DNIP: [Machine Learning: Künstliche Faultier-Intelligenz](https://dnip.ch/2022/08/16/machine-learning-kuenstliche-faultier-intelligenz/) Machine Learning („ML“) wird als Wundermittel angepriesen um die Menschheit von fast allen repetitiven Verarbeitungsaufgaben zu entlasten: Von der automatischen Klassifizierung von Strassenschilden über medizinische Auswertungen von Gewebeproben bis zur Auswahl und Einstellung neuer Mitarbeiter.
* DNIP: [Marcel pendelt: «KI» und «Vertrauen»](https://dnip.ch/2023/12/11/marcel-pendelt-ki-und-vertrauen/) Vor einigen Wochen hat Bruce Schneier einen Vortrag gehalten, bei dem er vor der der Vermischung und Fehlinterpretation des Begriffs «Vertrauen» gewarnt hat, ganz besonders beim Umgang mit dem, was heute von Firmen als «Künstliche Intelligenz» verkauft wird. Ich glaube, seine Überlegungen sollten einem breiteren Publikum präsentiert werden, deshalb hier das Wichtigste in Kürze auf Deutsch. (Das Original ist noch lesenswerter!)
* DNIP: [KI ist kein Zufall](https://dnip.ch/2023/05/08/ki-ist-kein-zufall/)
* DNIP: [ChatGPT besteht den Turing-Test, gilt KI jetzt als intelligent?](https://dnip.ch/2024/07/15/chatgpt-besteht-den-turing-test-gilt-ki-jetzt-als-intelligent/) In verschiedenen Medien (LiveScience, Slashdot, Heise, Netzwoche) wurde vor einigen Wochen berichtet, dass ChatGPT (konkret ChatGPT 4.0) den Turing-Test bestanden habe: Konkret waren bei einem Online-Experiment mit 500 Teilnehmenden 54% davon der Meinung, dass ihr Online-Chatpartner ein Mensch sei, obwohl sie sich mit einem Chatbot auf Basis von ChatGPT 4.0 unterhalten hatte. Was bedeutet das nun konkret?
* DNIP: [Was der Turing-Test für die Gesellschaft bedeutet](https://dnip.ch/2024/07/18/was-der-turing-test-fuer-die-gesellschaft-bedeutet/) Vor einem knappen Jahrhundert hat sich Alan Turing mit den Fundamenten der heutigen Informatik beschäftigt: Kryptographie, Komplexität/Rechenaufwand, aber auch, ob und wie wir erkennen könnten, ob Computer „intelligent“ seien.
* Deutschlandfunk: [Allgemeine KI -Wie weit noch bis zur Superintelligenz?](https://www.deutschlandfunk.de/wie-weit-noch-bis-zur-superintelligenz-dlf-a11e4806-100.html) Selbst Fachleute sind erstaunt über Fähigkeiten von KI, die in großen Sprachmodellen entstehen, ohne dass sie hineinprogrammiert wurden. Was passiert da gerade? Sind wir auf dem Weg in die maschinelle Superintelligenz – und muss uns das beunruhigen?
* Heise: [KI-Update Deep-Dive: Was versteht KI?](https://www.heise.de/news/KI-Update-Deep-Dive-Was-versteht-KI-10008028.html) Die Philosophieprofessorin Sybille Krämer erklärt, wie sich das Sprachverständnis von Mensch und Maschine unterscheidet und warum wir uns trotzdem verstehen.
